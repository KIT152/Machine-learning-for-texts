{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузим-и-изучим-данные\" data-toc-modified-id=\"Загрузим-и-изучим-данные-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузим и изучим данные</a></span></li><li><span><a href=\"#Лемматизируем-и-очистим-текст\" data-toc-modified-id=\"Лемматизируем-и-очистим-текст-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Лемматизируем и очистим текст</a></span></li><li><span><a href=\"#Сделаем-мешки-характерных-слов\" data-toc-modified-id=\"Сделаем-мешки-характерных-слов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Сделаем мешки характерных слов</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Разделим-данные-на-обучающую,-тестовую-и-валидационную-выборку\" data-toc-modified-id=\"Разделим-данные-на-обучающую,-тестовую-и-валидационную-выборку-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Разделим данные на обучающую, тестовую и валидационную выборку</a></span></li><li><span><a href=\"#Найдем-стоп-слова-и-переведем-в-векторы\" data-toc-modified-id=\"Найдем-стоп-слова-и-переведем-в-векторы-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Найдем стоп слова и переведем в векторы</a></span></li><li><span><a href=\"#Обучим-модель-LogisticRegressor\" data-toc-modified-id=\"Обучим-модель-LogisticRegressor-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Обучим модель LogisticRegressor</a></span></li><li><span><a href=\"#Обучим-модель-RandomForestClassifier\" data-toc-modified-id=\"Обучим-модель-RandomForestClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Обучим модель RandomForestClassifier</a></span></li><li><span><a href=\"#Обучим-модель-DecisionTreeClassifier\" data-toc-modified-id=\"Обучим-модель-DecisionTreeClassifier-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Обучим модель DecisionTreeClassifier</a></span></li><li><span><a href=\"#Проверим-модель-LogisticRegression-на-тестовой-выборке\" data-toc-modified-id=\"Проверим-модель-LogisticRegression-на-тестовой-выборке-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Проверим модель LogisticRegression на тестовой выборке</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим и изучим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import f1_score\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "               toxic\n",
      "count  159292.000000\n",
      "mean        0.101612\n",
      "std         0.302139\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "----------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "----------------------------\n",
      "Количество пропусков: text     0\n",
      "toxic    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "display(df.head())\n",
    "print('-'*28)\n",
    "print(df.describe())\n",
    "print('-'*28)\n",
    "print(df.info())\n",
    "print('-'*28)\n",
    "print('Количество пропусков:', df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные загружены корректно, но у целевого признака пристутствует явный дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизируем и очистим текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(text):   \n",
    "    tag = nltk.pos_tag([text])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(text):\n",
    "    reg = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear = reg.split() \n",
    "    lemm = [] \n",
    "    for i in range(len(clear)):\n",
    "        lemm.append(lemmatizer.lemmatize(clear[i], get_wordnet_pos(clear[i])))\n",
    "    return \" \".join(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 43s, sys: 1min 40s, total: 18min 24s\n",
      "Wall time: 18min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemmatize'] = df['text'].apply(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatize'] = df['lemmatize'].str.lower() #приветдем лемматезированный и  очищенный текст к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemmatize  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #проверим результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создали колонку с лемматизированным и очищенным текстом, а так же привели к нижему регистру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем мешки характерных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_bag(corpus):\n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    count_vect = CountVectorizer(max_features=20, stop_words=stop_words) \n",
    "    bow = count_vect.fit_transform(corpus)\n",
    "    \n",
    "    print(count_vect.get_feature_names())\n",
    "    \n",
    "#сделаем функцию для определения характерных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>hey what be it talk what be it an exclusive gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>bye don t look come or think of comming back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>you be gay or antisemmitian archangel white ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck your filthy mother in the ass dry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic  \\\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n",
       "16  Bye! \\n\\nDon't look, come or think of comming ...      1   \n",
       "42  You are gay or antisemmitian? \\n\\nArchangel WH...      1   \n",
       "43           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1   \n",
       "\n",
       "                                            lemmatize  \n",
       "6        cocksucker before you piss around on my work  \n",
       "12  hey what be it talk what be it an exclusive gr...  \n",
       "16  bye don t look come or think of comming back t...  \n",
       "42  you be gay or antisemmitian archangel white ti...  \n",
       "43             fuck your filthy mother in the ass dry  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_bag = df[df['toxic'] == 1] \n",
    "toxic_bag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article', 'bitch', 'block', 'die', 'faggot', 'fat', 'fuck', 'gay', 'get', 'go', 'hate', 'know', 'like', 'make', 'nigger', 'page', 'people', 'shit', 'suck', 'wikipedia']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(words_bag(list(toxic_bag['lemmatize'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemmatize  \n",
       "0  explanation why the edits make under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not try to edit war it s ju...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_toxic_bag = df[df['toxic'] == 0] \n",
    "no_toxic_bag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add', 'also', 'article', 'edit', 'get', 'know', 'like', 'make', 'one', 'page', 'please', 'say', 'see', 'source', 'talk', 'think', 'time', 'use', 'wikipedia', 'would']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(words_bag(list(no_toxic_bag['lemmatize'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определили характерные слов для токсичных и не токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим данные на обучающую, тестовую и валидационную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95575,)\n",
      "(95575,)\n",
      "(31858,)\n",
      "(31858,)\n",
      "(31859,)\n",
      "(31859,)\n"
     ]
    }
   ],
   "source": [
    "target = df['toxic']\n",
    "features = df['lemmatize']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=42, stratify=target) \n",
    "# stratify=target, чтобы сохранить соотношение классов\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_test, target_test, test_size=0.50, random_state=42, stratify=target_test)\n",
    "# stratify=target, чтобы сохранить соотношение классов\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    89.8%\n",
      "1    10.2%\n",
      "Name: toxic, dtype: object\n",
      "0    89.8%\n",
      "1    10.2%\n",
      "Name: toxic, dtype: object\n",
      "0    89.8%\n",
      "1    10.2%\n",
      "Name: toxic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(target_train.value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "print(target_valid.value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "print(target_test.value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
    "# проверим выборки на дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найдем стоп слова и переведем в векторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_idf = count_tf_idf.fit_transform(features_train)\n",
    "valid_tf_idf = count_tf_idf.transform(features_valid)\n",
    "test_tf_idf = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (95575, 117858)\n",
      "valid: (31858, 117858)\n",
      "test: (31859, 117858)\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\", train_tf_idf.shape)\n",
    "print(\"valid:\", valid_tf_idf.shape)\n",
    "print(\"test:\", test_tf_idf.shape)\n",
    "# Проверим размер матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель LogisticRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение С: 1\n",
      "F1_score: 0.7420094403236682\n",
      "----------------------------\n",
      "Значение С: 2\n",
      "F1_score: 0.7508232711306256\n",
      "----------------------------\n",
      "Значение С: 3\n",
      "F1_score: 0.7525687309080812\n",
      "----------------------------\n",
      "Значение С: 4\n",
      "F1_score: 0.756476683937824\n",
      "----------------------------\n",
      "Значение С: 5\n",
      "F1_score: 0.7546107278614669\n",
      "----------------------------\n",
      "Значение С: 6\n",
      "F1_score: 0.7544604927782498\n",
      "----------------------------\n",
      "Значение С: 7\n",
      "F1_score: 0.7541915316851379\n",
      "----------------------------\n",
      "Значение С: 8\n",
      "F1_score: 0.7553525549528975\n",
      "----------------------------\n",
      "Значение С: 9\n",
      "F1_score: 0.7553648068669527\n",
      "----------------------------\n",
      "\n",
      "CPU times: user 3min 40s, sys: 8min 23s, total: 12min 4s\n",
      "Wall time: 12min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for c in range(1, 10):\n",
    "    model_lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000, solver='lbfgs', C=c)\n",
    "    model_lr.fit(train_tf_idf, target_train)\n",
    "    predicted_valid_lr = model_lr.predict(valid_tf_idf)\n",
    "    print (\"Значение С:\", c)\n",
    "    print(\"F1_score:\", f1_score(target_valid, predicted_valid_lr))\n",
    "    print('-'*28)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель показала хороший результат, у параметра С=9 F1_score: 0.7659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина: 2\n",
      "F1_score: 0.2912723449001052\n",
      "----------------------------\n",
      "Глубина: 4\n",
      "F1_score: 0.2980759009248432\n",
      "----------------------------\n",
      "Глубина: 6\n",
      "F1_score: 0.32992116719614073\n",
      "----------------------------\n",
      "Глубина: 8\n",
      "F1_score: 0.3400133196100987\n",
      "----------------------------\n",
      "Глубина: 10\n",
      "F1_score: 0.3507025392224813\n",
      "----------------------------\n",
      "Глубина: 12\n",
      "F1_score: 0.3719932998324958\n",
      "----------------------------\n",
      "Глубина: 14\n",
      "F1_score: 0.3792697290930507\n",
      "----------------------------\n",
      "Глубина: 16\n",
      "F1_score: 0.38683821978485555\n",
      "----------------------------\n",
      "Глубина: 18\n",
      "F1_score: 0.3907203907203907\n",
      "----------------------------\n",
      "\n",
      "CPU times: user 38 s, sys: 270 ms, total: 38.2 s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for depth in range(2, 20, 2):\n",
    "    model_rf = RandomForestClassifier(class_weight='balanced', random_state=42, max_depth = depth)\n",
    "    model_rf.fit(train_tf_idf, target_train)\n",
    "    predicted_valid_rf = model_rf.predict(valid_tf_idf)\n",
    "    print('Глубина:', depth)\n",
    "    print(\"F1_score:\", f1_score(target_valid, predicted_valid_rf))    \n",
    "    print('-'*28)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель у глубины 16 - F1_score: 0.3927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество деревьев: 100\n",
      "F1_score: 0.38437478279001874\n",
      "----------------------------\n",
      "Количество деревьев: 200\n",
      "F1_score: 0.37643028434395337\n",
      "----------------------------\n",
      "Количество деревьев: 300\n",
      "F1_score: 0.3830142707970763\n",
      "----------------------------\n",
      "\n",
      "CPU times: user 38.6 s, sys: 240 ms, total: 38.8 s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for est in [100, 200, 300]:\n",
    "    model_rf = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=16, class_weight='balanced')\n",
    "    model_rf.fit(train_tf_idf, target_train)\n",
    "    predicted_valid_rf = model_rf.predict(valid_tf_idf)\n",
    "    print('Количество деревьев:', est)\n",
    "    print(\"F1_score:\", f1_score(target_valid, predicted_valid_rf))    \n",
    "    print('-'*28)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель с количеством деревьев 200 - F1_score: 0.3788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим модель DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Глубина: 2\n",
      "F1_score: 0.3711648790222\n",
      "----------------------------\n",
      "Глубина: 4\n",
      "F1_score: 0.4691075514874141\n",
      "----------------------------\n",
      "Глубина: 6\n",
      "F1_score: 0.5043821209465382\n",
      "----------------------------\n",
      "Глубина: 8\n",
      "F1_score: 0.5476987447698745\n",
      "----------------------------\n",
      "Глубина: 10\n",
      "F1_score: 0.5756097560975609\n",
      "----------------------------\n",
      "Глубина: 12\n",
      "F1_score: 0.5755395683453237\n",
      "----------------------------\n",
      "Глубина: 14\n",
      "F1_score: 0.5896088733216579\n",
      "----------------------------\n",
      "Глубина: 16\n",
      "F1_score: 0.5998093422306959\n",
      "----------------------------\n",
      "Глубина: 18\n",
      "F1_score: 0.5935973955507325\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(2, 20, 2):\n",
    "    model_dt = DecisionTreeClassifier(class_weight='balanced', random_state=42, max_depth=depth)\n",
    "    model_dt.fit(train_tf_idf, target_train)\n",
    "    predicted_valid_dt = model_dt.predict(valid_tf_idf)\n",
    "    print('Глубина:', depth)\n",
    "    print(\"F1_score:\", f1_score(target_valid, predicted_valid_dt))    \n",
    "    print('-'*28)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший показатель у глубины 18 - F1_score: 0.5891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим модель LogisticRegression на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.7565293093441673\n",
      "CPU times: user 32 s, sys: 1min 11s, total: 1min 43s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000, solver='lbfgs', C=9)\n",
    "model_lr.fit(train_tf_idf, target_train)\n",
    "predicted_test_lr = model_lr.predict(test_tf_idf)\n",
    "print(\"F1_score:\", f1_score(target_test, predicted_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1_score\n",
       "LogisticRegression          0.76\n",
       "DecisionTreeClassifier      0.58\n",
       "RandomForestClassifier      0.37"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [['LogisticRegression', 0.76],\n",
    "         ['DecisionTreeClassifier', 0.58],\n",
    "         ['RandomForestClassifier', 0.37]]\n",
    "table_result = pd.DataFrame(table, columns=['Модель','F1_score'])\n",
    "table_result = table_result.set_index('Модель')\n",
    "table_result.index.names = [None]\n",
    "table_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Загрузили и изучили данные\n",
    "* Лемматизировали и очистили текст\n",
    "* Сделали мешки характерных слов\n",
    "* Разделили данные на обучающую, тестовую и валидационную выборку\n",
    "* Нашли стоп слова и перевели в векторы\n",
    "* Обучили модель LogisticRegressor:\n",
    "    * Модель показала хороший результат F1_score: 0.7659\n",
    "* Обучили модель RandomForestClassifier:\n",
    "    * F1_score: 0.3927\n",
    "* Обучили модель DecisionTreeClassifier:\n",
    "    * F1_score: 0.5891\n",
    "* Проверили модель LogisticRegression на тестовой выборке:\n",
    "    * F1_score: 0.7631\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 347,
    "start_time": "2023-03-07T00:38:37.284Z"
   },
   {
    "duration": 2327,
    "start_time": "2023-03-07T00:38:59.624Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-07T00:39:08.792Z"
   },
   {
    "duration": 2032,
    "start_time": "2023-03-07T16:23:43.858Z"
   },
   {
    "duration": 5049,
    "start_time": "2023-03-07T16:23:45.893Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-07T16:23:50.944Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-07T16:24:12.816Z"
   },
   {
    "duration": 124,
    "start_time": "2023-03-07T16:24:29.117Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-07T16:29:43.493Z"
   },
   {
    "duration": 1822,
    "start_time": "2023-03-07T20:38:09.585Z"
   },
   {
    "duration": 3337,
    "start_time": "2023-03-07T20:38:11.410Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-07T20:38:14.749Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T20:38:14.833Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T20:38:14.841Z"
   },
   {
    "duration": 137,
    "start_time": "2023-03-07T20:40:31.926Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-07T20:40:53.688Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:40:54.402Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-07T20:40:54.882Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:44:04.577Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:44:06.715Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-07T20:44:07.848Z"
   },
   {
    "duration": 3457,
    "start_time": "2023-03-07T20:46:48.654Z"
   },
   {
    "duration": 753,
    "start_time": "2023-03-07T20:46:52.113Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-07T20:46:52.867Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T20:46:52.950Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:46:57.157Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:46:58.351Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:46:58.782Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:48:50.597Z"
   },
   {
    "duration": 569,
    "start_time": "2023-03-07T20:48:50.602Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:48:56.945Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:51:20.018Z"
   },
   {
    "duration": 520,
    "start_time": "2023-03-07T20:51:30.120Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:51:31.788Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T20:53:48.270Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:53:48.880Z"
   },
   {
    "duration": 499,
    "start_time": "2023-03-07T20:53:49.296Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:53:49.918Z"
   },
   {
    "duration": 250,
    "start_time": "2023-03-07T20:54:10.892Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-07T20:54:31.772Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:54:32.060Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:54:32.366Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-07T20:54:32.906Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-07T20:56:17.918Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T20:56:18.258Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T20:56:22.977Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:56:23.397Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T20:56:23.685Z"
   },
   {
    "duration": 665,
    "start_time": "2023-03-07T20:56:24.281Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:56:25.194Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T20:58:33.172Z"
   },
   {
    "duration": 218,
    "start_time": "2023-03-07T21:00:29.352Z"
   },
   {
    "duration": 4232,
    "start_time": "2023-03-07T21:00:38.965Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-07T21:00:52.732Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T21:03:01.861Z"
   },
   {
    "duration": 211,
    "start_time": "2023-03-07T21:03:03.073Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:03:28.638Z"
   },
   {
    "duration": 742,
    "start_time": "2023-03-07T21:03:29.899Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T21:04:43.586Z"
   },
   {
    "duration": 486134,
    "start_time": "2023-03-07T21:04:44.581Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:14:25.794Z"
   },
   {
    "duration": 807,
    "start_time": "2023-03-07T21:14:25.802Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-07T21:14:26.611Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:14:26.694Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:14:26.720Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:14:26.725Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T21:14:26.732Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T21:14:26.737Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:14:26.741Z"
   },
   {
    "duration": 4574,
    "start_time": "2023-03-07T21:16:08.829Z"
   },
   {
    "duration": 813,
    "start_time": "2023-03-07T21:16:13.406Z"
   },
   {
    "duration": 89,
    "start_time": "2023-03-07T21:16:14.221Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:16:14.322Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-07T21:16:14.331Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-07T21:16:14.368Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-07T21:16:14.435Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-07T21:16:14.478Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-07T21:16:14.506Z"
   },
   {
    "duration": 139,
    "start_time": "2023-03-07T21:16:14.560Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-07T21:16:14.701Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-07T21:16:14.702Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-07T21:16:14.704Z"
   },
   {
    "duration": 4547,
    "start_time": "2023-03-07T21:16:28.421Z"
   },
   {
    "duration": 819,
    "start_time": "2023-03-07T21:16:32.971Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-07T21:16:33.792Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:16:33.897Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:16:33.922Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:16:33.928Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:16:33.934Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:16:33.939Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:16:33.945Z"
   },
   {
    "duration": 4948,
    "start_time": "2023-03-07T21:16:33.952Z"
   },
   {
    "duration": 4404,
    "start_time": "2023-03-07T21:17:30.584Z"
   },
   {
    "duration": 788,
    "start_time": "2023-03-07T21:17:34.990Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-07T21:17:35.780Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:17:35.878Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-07T21:17:35.888Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:17:35.892Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:17:35.921Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:17:35.927Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-07T21:17:35.933Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-07T21:17:35.943Z"
   },
   {
    "duration": 3938,
    "start_time": "2023-03-07T21:17:35.969Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-07T21:17:39.909Z"
   },
   {
    "duration": 1443717,
    "start_time": "2023-03-07T21:18:31.355Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T21:42:35.074Z"
   },
   {
    "duration": 4421,
    "start_time": "2023-03-07T21:42:43.518Z"
   },
   {
    "duration": 816,
    "start_time": "2023-03-07T21:42:47.941Z"
   },
   {
    "duration": 95,
    "start_time": "2023-03-07T21:42:48.759Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:42:48.855Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:42:48.863Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-07T21:42:48.870Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:42:48.898Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:42:48.906Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:42:48.911Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:42:48.917Z"
   },
   {
    "duration": 4943,
    "start_time": "2023-03-07T21:42:48.925Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-07T21:42:53.870Z"
   },
   {
    "duration": 4176,
    "start_time": "2023-03-07T21:43:12.815Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-07T21:43:18.974Z"
   },
   {
    "duration": 3923,
    "start_time": "2023-03-07T21:43:36.100Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-07T21:43:43.792Z"
   },
   {
    "duration": 196,
    "start_time": "2023-03-07T21:46:02.221Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T21:46:04.906Z"
   },
   {
    "duration": 175,
    "start_time": "2023-03-07T21:46:23.273Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-07T21:46:24.167Z"
   },
   {
    "duration": 28114,
    "start_time": "2023-03-07T21:47:17.837Z"
   },
   {
    "duration": 4268,
    "start_time": "2023-03-07T21:47:55.312Z"
   },
   {
    "duration": 817,
    "start_time": "2023-03-07T21:47:59.582Z"
   },
   {
    "duration": 107,
    "start_time": "2023-03-07T21:48:00.401Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-07T21:48:00.510Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-07T21:48:00.528Z"
   },
   {
    "duration": 149,
    "start_time": "2023-03-07T21:48:00.566Z"
   },
   {
    "duration": 169,
    "start_time": "2023-03-07T21:48:00.716Z"
   },
   {
    "duration": 140,
    "start_time": "2023-03-07T21:48:00.887Z"
   },
   {
    "duration": 108,
    "start_time": "2023-03-07T21:48:01.029Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-07T21:48:01.139Z"
   },
   {
    "duration": 3884,
    "start_time": "2023-03-07T21:48:01.176Z"
   },
   {
    "duration": 4353,
    "start_time": "2023-03-07T21:52:36.903Z"
   },
   {
    "duration": 777,
    "start_time": "2023-03-07T21:52:41.258Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-07T21:52:42.037Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:52:42.130Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:52:42.137Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T21:52:42.145Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:52:42.160Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-07T21:52:42.167Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:52:42.176Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T21:52:42.182Z"
   },
   {
    "duration": 3714,
    "start_time": "2023-03-07T21:52:42.188Z"
   },
   {
    "duration": 66275,
    "start_time": "2023-03-07T21:52:45.904Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-07T21:53:52.181Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T21:53:52.376Z"
   },
   {
    "duration": 4380,
    "start_time": "2023-03-07T21:54:10.662Z"
   },
   {
    "duration": 812,
    "start_time": "2023-03-07T21:54:15.045Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-07T21:54:15.859Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-07T21:54:15.957Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-07T21:54:15.967Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:54:15.971Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:54:15.976Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T21:54:15.981Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T21:54:15.986Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T21:54:16.022Z"
   },
   {
    "duration": 72047,
    "start_time": "2023-03-07T21:54:16.027Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-07T21:55:28.076Z"
   },
   {
    "duration": 205,
    "start_time": "2023-03-07T21:55:28.080Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-07T21:55:28.288Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-07T21:58:29.079Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-07T22:00:34.087Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-07T22:00:47.055Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T22:00:54.478Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-07T22:01:25.513Z"
   },
   {
    "duration": 1118,
    "start_time": "2023-03-07T22:04:34.985Z"
   },
   {
    "duration": 831,
    "start_time": "2023-03-07T22:04:58.788Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-07T22:05:18.481Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T22:06:12.832Z"
   },
   {
    "duration": 553,
    "start_time": "2023-03-07T22:06:21.797Z"
   },
   {
    "duration": 543,
    "start_time": "2023-03-07T22:07:54.632Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T22:11:17.678Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T22:11:50.014Z"
   },
   {
    "duration": 46,
    "start_time": "2023-03-07T22:13:07.771Z"
   },
   {
    "duration": 572,
    "start_time": "2023-03-07T22:13:22.618Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-07T22:16:26.194Z"
   },
   {
    "duration": 6398,
    "start_time": "2023-03-07T22:16:46.441Z"
   },
   {
    "duration": 93,
    "start_time": "2023-03-07T22:24:31.172Z"
   },
   {
    "duration": 136,
    "start_time": "2023-03-07T22:25:10.190Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-07T22:27:07.147Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-07T22:29:06.932Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-07T22:36:40.697Z"
   },
   {
    "duration": 6657,
    "start_time": "2023-03-07T22:37:09.485Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-07T22:40:29.710Z"
   },
   {
    "duration": 89431,
    "start_time": "2023-03-07T22:45:31.900Z"
   },
   {
    "duration": 40519,
    "start_time": "2023-03-07T22:47:36.711Z"
   },
   {
    "duration": 47100,
    "start_time": "2023-03-07T22:53:10.522Z"
   },
   {
    "duration": 35974,
    "start_time": "2023-03-07T23:08:09.832Z"
   },
   {
    "duration": 34994,
    "start_time": "2023-03-07T23:10:32.451Z"
   },
   {
    "duration": 38241,
    "start_time": "2023-03-07T23:13:55.801Z"
   },
   {
    "duration": 47497,
    "start_time": "2023-03-07T23:17:25.852Z"
   },
   {
    "duration": 39792,
    "start_time": "2023-03-07T23:21:47.645Z"
   },
   {
    "duration": 47478,
    "start_time": "2023-03-07T23:22:30.259Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-07T23:23:31.738Z"
   },
   {
    "duration": 87986,
    "start_time": "2023-03-07T23:23:39.346Z"
   },
   {
    "duration": 36353,
    "start_time": "2023-03-07T23:27:26.388Z"
   },
   {
    "duration": 4348,
    "start_time": "2023-03-07T23:28:15.403Z"
   },
   {
    "duration": 786,
    "start_time": "2023-03-07T23:28:19.753Z"
   },
   {
    "duration": 92,
    "start_time": "2023-03-07T23:28:20.540Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-07T23:28:20.634Z"
   },
   {
    "duration": 14,
    "start_time": "2023-03-07T23:28:20.642Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-07T23:28:20.658Z"
   },
   {
    "duration": 17,
    "start_time": "2023-03-07T23:28:20.668Z"
   },
   {
    "duration": 73110,
    "start_time": "2023-03-07T23:28:20.687Z"
   },
   {
    "duration": 209,
    "start_time": "2023-03-07T23:29:33.798Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-07T23:29:34.009Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-07T23:29:34.026Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-07T23:29:34.038Z"
   },
   {
    "duration": 572,
    "start_time": "2023-03-07T23:29:34.107Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-07T23:29:34.682Z"
   },
   {
    "duration": 6398,
    "start_time": "2023-03-07T23:29:34.705Z"
   },
   {
    "duration": 102,
    "start_time": "2023-03-07T23:29:41.105Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-07T23:29:41.208Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-07T23:29:41.230Z"
   },
   {
    "duration": 6979,
    "start_time": "2023-03-07T23:29:41.234Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-07T23:29:48.215Z"
   },
   {
    "duration": 767009,
    "start_time": "2023-03-07T23:29:48.227Z"
   },
   {
    "duration": 35188,
    "start_time": "2023-03-07T23:42:35.238Z"
   },
   {
    "duration": 38082,
    "start_time": "2023-03-07T23:43:10.428Z"
   },
   {
    "duration": 46728,
    "start_time": "2023-03-07T23:43:48.512Z"
   },
   {
    "duration": 88494,
    "start_time": "2023-03-07T23:44:35.241Z"
   },
   {
    "duration": 41252,
    "start_time": "2023-03-07T23:47:12.072Z"
   },
   {
    "duration": 321,
    "start_time": "2023-03-07T23:50:17.798Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-07T23:50:24.977Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-07T23:51:19.241Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-07T23:51:29.636Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-07T23:53:59.475Z"
   },
   {
    "duration": 4285,
    "start_time": "2023-03-08T00:01:35.954Z"
   },
   {
    "duration": 820,
    "start_time": "2023-03-08T00:01:40.245Z"
   },
   {
    "duration": 91,
    "start_time": "2023-03-08T00:01:41.067Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-08T00:01:41.160Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-08T00:01:41.169Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-08T00:01:41.173Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-08T00:01:41.182Z"
   },
   {
    "duration": 75359,
    "start_time": "2023-03-08T00:01:41.191Z"
   },
   {
    "duration": 199,
    "start_time": "2023-03-08T00:02:56.551Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-08T00:02:56.752Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-08T00:02:56.763Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-08T00:02:56.776Z"
   },
   {
    "duration": 571,
    "start_time": "2023-03-08T00:02:56.845Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-08T00:02:57.422Z"
   },
   {
    "duration": 6305,
    "start_time": "2023-03-08T00:02:57.446Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-08T00:03:03.753Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-08T00:03:03.856Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T00:03:03.869Z"
   },
   {
    "duration": 6940,
    "start_time": "2023-03-08T00:03:03.874Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-08T00:03:10.816Z"
   },
   {
    "duration": 727798,
    "start_time": "2023-03-08T00:03:10.826Z"
   },
   {
    "duration": 32370,
    "start_time": "2023-03-08T00:15:18.626Z"
   },
   {
    "duration": 33879,
    "start_time": "2023-03-08T00:15:50.998Z"
   },
   {
    "duration": 44890,
    "start_time": "2023-03-08T00:16:24.879Z"
   },
   {
    "duration": 97452,
    "start_time": "2023-03-08T00:17:09.771Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-08T00:18:47.225Z"
   },
   {
    "duration": 11456,
    "start_time": "2023-03-08T10:56:23.573Z"
   },
   {
    "duration": 3608,
    "start_time": "2023-03-08T10:56:55.922Z"
   },
   {
    "duration": 81,
    "start_time": "2023-03-08T10:57:02.738Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-08T10:57:17.233Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T10:57:21.638Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T10:57:22.358Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-08T11:16:54.722Z"
   },
   {
    "duration": 352,
    "start_time": "2023-03-08T11:17:06.212Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-08T11:17:56.102Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:19:12.031Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:19:12.563Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:19:13.000Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:19:13.771Z"
   },
   {
    "duration": 297,
    "start_time": "2023-03-08T11:19:19.133Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:19:42.332Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:19:42.891Z"
   },
   {
    "duration": 281,
    "start_time": "2023-03-08T11:19:44.524Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:20:19.340Z"
   },
   {
    "duration": 281,
    "start_time": "2023-03-08T11:20:19.976Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:27:33.092Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:28:41.057Z"
   },
   {
    "duration": 85,
    "start_time": "2023-03-08T11:28:41.798Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-08T11:28:59.492Z"
   },
   {
    "duration": 4174,
    "start_time": "2023-03-08T11:29:12.608Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:37:03.926Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-08T11:41:06.292Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:42:40.821Z"
   },
   {
    "duration": 775,
    "start_time": "2023-03-08T11:42:40.827Z"
   },
   {
    "duration": 69,
    "start_time": "2023-03-08T11:42:41.604Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-08T11:42:41.675Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:42:41.683Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:42:41.687Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-08T11:42:41.713Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-08T11:42:41.726Z"
   },
   {
    "duration": 1731,
    "start_time": "2023-03-08T11:42:41.741Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:42:43.474Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-08T11:42:43.479Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:42:43.486Z"
   },
   {
    "duration": 2081,
    "start_time": "2023-03-08T11:42:43.490Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-08T11:43:15.905Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:44:01.282Z"
   },
   {
    "duration": 811,
    "start_time": "2023-03-08T11:44:01.287Z"
   },
   {
    "duration": 71,
    "start_time": "2023-03-08T11:44:02.099Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-08T11:44:02.171Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T11:44:02.179Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:44:02.183Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-08T11:44:02.188Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-08T11:44:02.225Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T11:44:02.294Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-08T11:44:02.300Z"
   },
   {
    "duration": 1094044,
    "start_time": "2023-03-08T11:44:02.335Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-08T12:02:38.740Z"
   },
   {
    "duration": 4103,
    "start_time": "2023-03-08T12:05:39.212Z"
   },
   {
    "duration": 743,
    "start_time": "2023-03-08T12:05:43.317Z"
   },
   {
    "duration": 99,
    "start_time": "2023-03-08T12:05:44.063Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-08T12:05:44.165Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T12:05:44.174Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-08T12:05:44.179Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-08T12:05:44.186Z"
   },
   {
    "duration": 244,
    "start_time": "2023-03-08T12:05:44.215Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T12:05:44.461Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T12:05:44.467Z"
   },
   {
    "duration": 363,
    "start_time": "2023-03-08T12:05:44.472Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-08T12:05:44.837Z"
   },
   {
    "duration": 774,
    "start_time": "2023-03-08T12:05:44.849Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.625Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.626Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.627Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.629Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.630Z"
   },
   {
    "duration": 1,
    "start_time": "2023-03-08T12:05:45.631Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.633Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.634Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.635Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.635Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.636Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.638Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.640Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.642Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.643Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.644Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-08T12:05:45.645Z"
   },
   {
    "duration": 66,
    "start_time": "2023-03-08T12:06:49.467Z"
   },
   {
    "duration": 4239,
    "start_time": "2023-03-08T12:08:50.015Z"
   },
   {
    "duration": 755,
    "start_time": "2023-03-08T12:08:54.258Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-08T12:08:55.015Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-08T12:08:55.089Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-08T12:08:55.115Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-08T12:08:55.119Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T12:08:55.126Z"
   },
   {
    "duration": 326,
    "start_time": "2023-03-08T12:08:55.132Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T12:08:55.459Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-08T12:08:55.464Z"
   },
   {
    "duration": 1105713,
    "start_time": "2023-03-08T12:08:55.478Z"
   },
   {
    "duration": 207,
    "start_time": "2023-03-08T12:27:21.193Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-08T12:27:21.402Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-08T12:27:21.415Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-08T12:27:21.422Z"
   },
   {
    "duration": 542,
    "start_time": "2023-03-08T12:27:21.464Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-08T12:27:22.013Z"
   },
   {
    "duration": 6234,
    "start_time": "2023-03-08T12:27:22.034Z"
   },
   {
    "duration": 94,
    "start_time": "2023-03-08T12:27:28.270Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-08T12:27:28.366Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T12:27:28.377Z"
   },
   {
    "duration": 6674,
    "start_time": "2023-03-08T12:27:28.382Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-08T12:27:35.058Z"
   },
   {
    "duration": 725256,
    "start_time": "2023-03-08T12:27:35.063Z"
   },
   {
    "duration": 38286,
    "start_time": "2023-03-08T12:39:40.322Z"
   },
   {
    "duration": 38919,
    "start_time": "2023-03-08T12:40:18.612Z"
   },
   {
    "duration": 44391,
    "start_time": "2023-03-08T12:40:57.532Z"
   },
   {
    "duration": 103901,
    "start_time": "2023-03-08T12:41:41.924Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-08T12:43:25.829Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.388px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
